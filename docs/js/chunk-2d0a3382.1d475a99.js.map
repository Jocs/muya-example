{"version":3,"sources":["webpack:///./node_modules/prismjs2/components/prism-markup-templating.js"],"names":["Prism","languages","Object","defineProperties","buildPlaceholders","value","env","language","placeholderPattern","replaceFilter","tokenStack","code","replace","match","i","length","indexOf","toUpperCase","grammar","markup","tokenizePlaceholders","j","keys","walkTokens","tokens","token","content","k","t","s","index","replacement","before","substring","middle","Token","tokenize","after","filter","v","Array","prototype","splice","apply","concat"],"mappings":"mGAAAA,MAAAC,UAAA,wBAEAC,OAAAC,iBAAAH,MAAAC,UAAA,sBACAG,kBAAA,CAIAC,MAAA,SAAAC,EAAAC,EAAAC,EAAAC,GACAH,EAAAC,eAIAD,EAAAI,WAAA,GAEAJ,EAAAK,KAAAL,EAAAK,KAAAC,QAAAJ,EAAA,SAAAK,GACA,uBAAAJ,MAAAI,GACA,OAAAA,EAEA,IAAAC,EAAAR,EAAAI,WAAAK,OAEA,WAAAT,EAAAK,KAAAK,QAAA,MAAAT,EAAAU,cAAAH,EAAA,SACAA,EAKA,OAFAR,EAAAI,WAAAI,GAAAD,EAEA,MAAAN,EAAAU,cAAAH,EAAA,QAIAR,EAAAY,QAAAlB,MAAAC,UAAAkB,UAGAC,qBAAA,CAEAf,MAAA,SAAAC,EAAAC,GACA,GAAAD,EAAAC,cAAAD,EAAAI,WAAA,CAKAJ,EAAAY,QAAAlB,MAAAC,UAAAM,GAEA,IAAAc,EAAA,EACAC,EAAApB,OAAAoB,KAAAhB,EAAAI,YACAa,EAAA,SAAAC,GACA,KAAAH,GAAAC,EAAAP,QAGA,QAAAD,EAAA,EAAmBA,EAAAU,EAAAT,OAAmBD,IAAA,CACtC,IAAAW,EAAAD,EAAAV,GACA,qBAAAW,KAAAC,SAAA,kBAAAD,EAAAC,QAAA,CACA,IAAAC,EAAAL,EAAAD,GACAO,EAAAtB,EAAAI,WAAAiB,GACAE,EAAA,kBAAAJ,MAAAC,QAEAI,EAAAD,EAAAb,QAAA,MAAAT,EAAAU,cAAAU,EAAA,OACA,GAAAG,GAAA,KACAT,EACA,IAGAU,EAHAC,EAAAH,EAAAI,UAAA,EAAAH,GACAI,EAAA,IAAAlC,MAAAmC,MAAA5B,EAAAP,MAAAoC,SAAAR,EAAAtB,EAAAY,QAAAX,GAAA,YAAAA,EAAAqB,GACAS,EAAAR,EAAAI,UAAAH,GAAA,MAAAvB,EAAAU,cAAAU,EAAA,OAAAZ,QAcA,GAZAiB,GAAAK,GACAN,EAAA,CAAAC,EAAAE,EAAAG,GAAAC,OAAA,SAAAC,GAAmE,QAAAA,IACnEhB,EAAAQ,IAEAA,EAAAG,EAEA,kBAAAT,EACAe,MAAAC,UAAAC,OAAAC,MAAAnB,EAAA,CAAAV,EAAA,GAAA8B,OAAAb,IAEAN,EAAAC,QAAAK,EAGAV,GAAAC,EAAAP,OACA,YAGMU,EAAAC,SAAA,kBAAAD,EAAAC,SACNH,EAAAE,EAAAC,WAKAH,EAAAjB,EAAAkB","file":"js/chunk-2d0a3382.1d475a99.js","sourcesContent":["Prism.languages['markup-templating'] = {};\n\nObject.defineProperties(Prism.languages['markup-templating'], {\n\tbuildPlaceholders: {\n\t\t// Tokenize all inline templating expressions matching placeholderPattern\n\t\t// If the replaceFilter function is provided, it will be called with every match.\n\t\t// If it returns false, the match will not be replaced.\n\t\tvalue: function (env, language, placeholderPattern, replaceFilter) {\n\t\t\tif (env.language !== language) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tenv.tokenStack = [];\n\n\t\t\tenv.code = env.code.replace(placeholderPattern, function(match) {\n\t\t\t\tif (typeof replaceFilter === 'function' && !replaceFilter(match)) {\n\t\t\t\t\treturn match;\n\t\t\t\t}\n\t\t\t\tvar i = env.tokenStack.length;\n\t\t\t\t// Check for existing strings\n\t\t\t\twhile (env.code.indexOf('___' + language.toUpperCase() + i + '___') !== -1)\n\t\t\t\t\t++i;\n\n\t\t\t\t// Create a sparse array\n\t\t\t\tenv.tokenStack[i] = match;\n\n\t\t\t\treturn '___' + language.toUpperCase() + i + '___';\n\t\t\t});\n\n\t\t\t// Switch the grammar to markup\n\t\t\tenv.grammar = Prism.languages.markup;\n\t\t}\n\t},\n\ttokenizePlaceholders: {\n\t\t// Replace placeholders with proper tokens after tokenizing\n\t\tvalue: function (env, language) {\n\t\t\tif (env.language !== language || !env.tokenStack) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// Switch the grammar back\n\t\t\tenv.grammar = Prism.languages[language];\n\n\t\t\tvar j = 0;\n\t\t\tvar keys = Object.keys(env.tokenStack);\n\t\t\tvar walkTokens = function (tokens) {\n\t\t\t\tif (j >= keys.length) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tfor (var i = 0; i < tokens.length; i++) {\n\t\t\t\t\tvar token = tokens[i];\n\t\t\t\t\tif (typeof token === 'string' || (token.content && typeof token.content === 'string')) {\n\t\t\t\t\t\tvar k = keys[j];\n\t\t\t\t\t\tvar t = env.tokenStack[k];\n\t\t\t\t\t\tvar s = typeof token === 'string' ? token : token.content;\n\n\t\t\t\t\t\tvar index = s.indexOf('___' + language.toUpperCase() + k + '___');\n\t\t\t\t\t\tif (index > -1) {\n\t\t\t\t\t\t\t++j;\n\t\t\t\t\t\t\tvar before = s.substring(0, index);\n\t\t\t\t\t\t\tvar middle = new Prism.Token(language, Prism.tokenize(t, env.grammar, language), 'language-' + language, t);\n\t\t\t\t\t\t\tvar after = s.substring(index + ('___' + language.toUpperCase() + k + '___').length);\n\t\t\t\t\t\t\tvar replacement;\n\t\t\t\t\t\t\tif (before || after) {\n\t\t\t\t\t\t\t\treplacement = [before, middle, after].filter(function (v) { return !!v; });\n\t\t\t\t\t\t\t\twalkTokens(replacement);\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\treplacement = middle;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (typeof token === 'string') {\n\t\t\t\t\t\t\t\tArray.prototype.splice.apply(tokens, [i, 1].concat(replacement));\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\ttoken.content = replacement;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (j >= keys.length) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (token.content && typeof token.content !== 'string') {\n\t\t\t\t\t\twalkTokens(token.content);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\n\t\t\twalkTokens(env.tokens);\n\t\t}\n\t}\n});"],"sourceRoot":""}